name: Daily AI PR Health Sweep

on:
   schedule:
      # Midnight JST = 15:00 UTC
      - cron: "0 15 * * *"
   workflow_dispatch:

permissions:
   contents: read
   issues: write
   pull-requests: read
   actions: read
   models: read

jobs:
   scan-prs:
      runs-on: ubuntu-latest
      outputs:
         pr_list: ${{ steps.set.outputs.pr_list }}
      steps:
         - name: Compute JST window for yesterday
           id: date
           run: |
              # Compute start of yesterday/today in JST and convert to UTC
              # Uses tzdata to shift from Asia/Tokyo to UTC
              utc_since=$(TZ=Asia/Tokyo date -d 'yesterday 00:00' -u +%Y-%m-%dT%H:%M:%SZ)
              utc_until=$(TZ=Asia/Tokyo date -d 'today 00:00' -u +%Y-%m-%dT%H:%M:%SZ)
              echo "utc_since=$utc_since" >> $GITHUB_OUTPUT
              echo "utc_until=$utc_until" >> $GITHUB_OUTPUT

         - name: List yesterday’s PRs (JST window, including reopened)
           id: list_prs
           uses: actions/github-script@v7
           with:
              script: |
                 const since = process.env.UTC_SINCE;
                 const until = process.env.UTC_UNTIL;
                 const prs = await github.paginate(github.rest.pulls.list, {
                   owner: context.repo.owner,
                   repo: context.repo.repo,
                   state: "all",
                   per_page: 100
                 });

                 const target = new Set();
                 const inWindow = (d) => d && d >= new Date(since) && d < new Date(until);

                 for (const pr of prs) {
                   const created = new Date(pr.created_at);
                   const closedAt = pr.closed_at ? new Date(pr.closed_at) : null;
                   const mergedAt = pr.merged_at ? new Date(pr.merged_at) : null;
                   if (inWindow(created) || inWindow(closedAt) || inWindow(mergedAt)) {
                     target.add(pr.number);
                     continue;
                   }

                   // Fetch issue events to detect reopen
                   const events = await github.paginate(github.rest.issues.listEvents, {
                     owner: context.repo.owner,
                     repo: context.repo.repo,
                     issue_number: pr.number,
                     per_page: 100
                   });

                   const matchedEvent = events.some(e =>
                     (e.event === "reopened" || e.event === "closed") &&
                     inWindow(new Date(e.created_at))
                   );

                   if (matchedEvent) {
                     target.add(pr.number);
                   }
                 }

                 return Array.from(target);
           env:
              UTC_SINCE: ${{ steps.date.outputs.utc_since }}
              UTC_UNTIL: ${{ steps.date.outputs.utc_until }}

         - name: Set PR list output
           id: set
           run: echo "pr_list=${{ steps.list_prs.outputs.result }}" >> $GITHUB_OUTPUT

   analyze-prs:
      needs: scan-prs
      runs-on: ubuntu-latest
      env:
         GH_TOKEN: ${{ github.token }}
      if: ${{ needs.scan-prs.outputs.pr_list != '[]' }}
      strategy:
         matrix:
            pr: ${{ fromJSON(needs.scan-prs.outputs.pr_list) }}
      steps:
         - name: Get PR details
           id: details
           uses: actions/github-script@v7
           with:
              script: |
                 const pr = await github.rest.pulls.get({
                   owner: context.repo.owner,
                   repo: context.repo.repo,
                   pull_number: ${{ matrix.pr }}
                 });
                 return pr.data;

         - name: Get last CI status
           id: status
           uses: actions/github-script@v7
           with:
              script: |
                 // List latest workflow runs for the repo on this branch
                 // Note: listWorkflowRuns requires a workflow_id; we want all, so use listWorkflowRunsForRepo
                 const runs = await github.rest.actions.listWorkflowRunsForRepo({
                   owner: context.repo.owner,
                   repo: context.repo.repo,
                   branch: '${{ fromJSON(steps.details.outputs.result).head.ref }}',
                   per_page: 1
                 });
                 if (runs.data.workflow_runs.length) {
                   return runs.data.workflow_runs[0].conclusion || "unknown";
                 }
                 return "no-run";

         - name: Fetch logs
           run: |
              set -euo pipefail
              REPO="$GITHUB_REPOSITORY"
              BRANCH="${{ fromJSON(steps.details.outputs.result).head.ref }}"
              RUN_ID=$(gh run list --repo "$REPO" --branch "$BRANCH" --json databaseId --jq '.[0].databaseId' || true)
              if [ -n "${RUN_ID:-}" ]; then
                # Try to fetch logs; if unavailable (expired/no-access), write a friendly placeholder.
                if ! gh run view --repo "$REPO" "$RUN_ID" --log > ci_logs.txt 2> gh_err.txt; then
                  echo "Warning: failed to fetch logs for run '$RUN_ID' on branch '$BRANCH'" >&2 || true
                  if [ -s gh_err.txt ]; then
                    echo "gh error: $(head -n1 gh_err.txt)" >&2 || true
                  fi
                  echo "Logs unavailable for run '$RUN_ID' on branch '$BRANCH' (may be expired or inaccessible)." > ci_logs.txt || true
                fi
                rm -f gh_err.txt || true
              else
                echo "No workflow runs found for branch '$BRANCH'" > ci_logs.txt
              fi

         - name: Build AI prompt
           run: |
              set -euo pipefail
              TITLE="${{ fromJSON(steps.details.outputs.result).title }}"
              # Sanitize logs: strip non-printable/ANSI, then hard-cap size to avoid model 8k token limit
              if [ -f ci_logs.txt ]; then
                sed -E 's/[^[:print:]\t]//g' ci_logs.txt > ci_logs_clean.txt || cp ci_logs.txt ci_logs_clean.txt
                # Keep only the last ~15KB to stay well under token limits
                tail -c 15000 ci_logs_clean.txt > ci_logs_cropped.txt || cp ci_logs_clean.txt ci_logs_cropped.txt
              else
                echo "ci_logs.txt not found." > ci_logs_cropped.txt
              fi

              {
                echo "PR Title: ${TITLE}"
                echo
                echo "Logs (cropped to last ~15KB):"
                cat ci_logs_cropped.txt
              } > ai_prompt.txt

         - name: AI severity + summary
           id: ai
           uses: actions/ai-inference@v1
           with:
              system-prompt: >-
                You are an expert reviewer. Classify CI failure severity (critical/moderate/minor/none)
                and summarize issues. Return JSON: {"severity":...,"summary":...}.
              prompt-file: ai_prompt.txt
              model: openai/gpt-4o
              endpoint: https://models.github.ai/inference
              max-tokens: 200
              token: ${{ github.token }}

         - name: Parse AI result
           if: ${{ steps.status.outputs.result == 'failure' }}
           id: parse
           run: |
              echo '${{ steps.ai.outputs.message }}' | jq -r '.severity,.summary' \
                | awk 'NR==1{print "severity="$0} NR==2{print "summary="$0}' >> $GITHUB_OUTPUT

         - name: Search existing issue
           id: search
           uses: actions/github-script@v7
           with:
              script: |
                 const prNumber = "${{ matrix.pr }}";
                 const issues = await github.rest.search.issuesAndPullRequests({
                   q: `repo:${context.repo.owner}/${context.repo.repo} in:title "AI Review: PR #${prNumber}"`
                 });
                 return issues.data.items.length ? issues.data.items[0] : null;

         - name: Close and comment on fix
           if: ${{ steps.status.outputs.result == 'success' && steps.search.outputs.result != 'null' }}
           uses: actions/github-script@v7
           with:
              script: |
                 const issue = JSON.parse('${{ steps.search.outputs.result }}');
                 const now = new Date().toISOString();
                 await github.rest.issues.createComment({
                   owner: context.repo.owner,
                   repo: context.repo.repo,
                   issue_number: issue.number,
                   body: `### [${now}] CI Passed\nAuto-closing issue.`
                 });
                 await github.rest.issues.update({
                   owner: context.repo.owner,
                   repo: context.repo.repo,
                   issue_number: issue.number,
                   state: "closed"
                 });

         - name: Create or comment on failure
           if: ${{ steps.status.outputs.result == 'failure' && steps.parse.outputs.severity != 'none' }}
           uses: actions/github-script@v7
           with:
              script: |
                 const prNumber = "${{ matrix.pr }}";
                 const issue = JSON.parse('${{ steps.search.outputs.result }}');
                 const severity = "${{ steps.parse.outputs.severity }}";
                 const summary = "${{ steps.parse.outputs.summary }}";
                 const now = new Date().toISOString();
                 const commentBody = `### [${now}] CI Failure Analysis\n**Severity:** ${severity}\n\n${summary}`;

                 if (issue) {
                   await github.rest.issues.createComment({
                     owner: context.repo.owner,
                     repo: context.repo.repo,
                     issue_number: issue.number,
                     body: commentBody
                   });

                   await github.rest.issues.update({
                     owner: context.repo.owner,
                     repo: context.repo.repo,
                     issue_number: issue.number,
                     state: "open",
                     labels: ["ai-review", "ci-failure", `severity:${severity}`]
                   });
                 } else {
                   await github.rest.issues.create({
                     owner: context.repo.owner,
                     repo: context.repo.repo,
                     title: `AI Review: PR #${prNumber}`,
                     body: `Tracking CI health for PR #${prNumber}. Auto-updated daily.`,
                     labels: ["ai-review", "ci-failure", `severity:${severity}`]
                   });

                   const newIssue = await github.rest.issues.listForRepo({
                     owner: context.repo.owner,
                     repo: context.repo.repo,
                     labels: "ai-review,ci-failure",
                     state: "open",
                     per_page: 1,
                     sort: "created",
                     direction: "desc"
                   });
                   await github.rest.issues.createComment({
                     owner: context.repo.owner,
                     repo: context.repo.repo,
                     issue_number: newIssue.data[0].number,
                     body: commentBody
                   });
                 }

   daily-digest:
     needs: analyze-prs
     runs-on: ubuntu-latest
     env:
        GH_TOKEN: ${{ github.token }}
     steps:
        - name: Compute JST window for yesterday (digest)
          id: date_digest
          run: |
             utc_since=$(TZ=Asia/Tokyo date -d 'yesterday 00:00' -u +%Y-%m-%dT%H:%M:%SZ)
             utc_until=$(TZ=Asia/Tokyo date -d 'today 00:00' -u +%Y-%m-%dT%H:%M:%SZ)
             echo "utc_since=$utc_since" >> $GITHUB_OUTPUT
             echo "utc_until=$utc_until" >> $GITHUB_OUTPUT

        - name: Checkout repository
          uses: actions/checkout@v4
          with:
             fetch-depth: 0

        - name: Collect PR activity stats
          id: pr_stats
          run: |
             set -euo pipefail
             REPO="$GITHUB_REPOSITORY"
             SINCE="${{ steps.date_digest.outputs.utc_since }}"
             UNTIL="${{ steps.date_digest.outputs.utc_until }}"

             opened=$(gh api search/issues -f q="repo:$REPO is:pr created:>=$SINCE created:<$UNTIL" --jq .total_count)
             merged=$(gh api search/issues -f q="repo:$REPO is:pr is:merged merged:>=$SINCE merged:<$UNTIL" --jq .total_count)
             closed_not_merged=$(gh api search/issues -f q="repo:$REPO is:pr is:closed -is:merged closed:>=$SINCE closed:<$UNTIL" --jq .total_count)

             echo "opened=$opened" >> $GITHUB_OUTPUT
             echo "merged=$merged" >> $GITHUB_OUTPUT
             echo "closed_not_merged=$closed_not_merged" >> $GITHUB_OUTPUT

        - name: Collect CI failure issues (window)
          id: ci_failures
          run: |
             set -euo pipefail
             REPO="$GITHUB_REPOSITORY"
             SINCE="${{ steps.date_digest.outputs.utc_since }}"
             UNTIL="${{ steps.date_digest.outputs.utc_until }}"
             # Use REST search API to list issues labeled as CI failures in window
             gh api search/issues -f q="repo:$REPO is:issue label:ai-review label:ci-failure updated:>=$SINCE updated:<$UNTIL" \
               --jq '[.items[] | {number: .number, title: .title, url: .html_url, updatedAt: .updated_at, severity: ((.labels // []) | map(.name) | map(select(startswith("severity:"))) | first // "severity:unknown")}]' > ci_failures.json || echo '[]' > ci_failures.json
             echo "count=$(jq length ci_failures.json)" >> $GITHUB_OUTPUT

        - name: Compute git activity (since/until)
          id: git_stats
          run: |
             set -euo pipefail
             SINCE="${{ steps.date_digest.outputs.utc_since }}"
             UNTIL="${{ steps.date_digest.outputs.utc_until }}"
             # Commits count
             commits=$(git log --since="$SINCE" --until="$UNTIL" --pretty=format:'%H' | wc -l | tr -d ' ')
             echo "commits=$commits" >> $GITHUB_OUTPUT

             # Top authors (name and count) - top 5
             git log --since="$SINCE" --until="$UNTIL" --pretty=format:'%an' | \
               awk '{a[$0]++} END {for (k in a) printf "%s\t%s\n", a[k], k}' | \
               sort -rn | head -5 > top_authors.txt || true

             # Top-level directories with most changes (top 5)
             git log --since="$SINCE" --until="$UNTIL" --name-only --pretty=format: | \
               grep -v '^$' | awk -F/ '{print $1}' | \
               grep -vE '^(\.|README(\..*)?|LICENSE(\..*)?)$' | \
               awk '{d[$0]++} END {for (k in d) printf "%s\t%s\n", d[k], k}' | \
               sort -rn | head -5 > top_dirs.txt || true

        - name: Build digest markdown
          run: |
             set -euo pipefail
             SINCE="${{ steps.date_digest.outputs.utc_since }}"
             UNTIL="${{ steps.date_digest.outputs.utc_until }}"
             DATE_JST=$(TZ=Asia/Tokyo date -d "${SINCE}" +%Y-%m-%d)
             OPENED='${{ steps.pr_stats.outputs.opened }}'
             MERGED='${{ steps.pr_stats.outputs.merged }}'
             CLOSED='${{ steps.pr_stats.outputs.closed_not_merged }}'
             COMMITS='${{ steps.git_stats.outputs.commits }}'
             CI_FAIL_COUNT='${{ steps.ci_failures.outputs.count }}'

             {
               echo "### Daily Activity Summary (${DATE_JST} JST Window)"
               echo
               echo "- PRs opened: ${OPENED}"
               echo "- PRs merged: ${MERGED}"
               echo "- PRs closed (unmerged): ${CLOSED}"
               echo "- Commits: ${COMMITS}"
               echo "- CI failure issues updated: ${CI_FAIL_COUNT}"
               echo
               echo "### Top Authors"
               if [ -s top_authors.txt ]; then
                 awk -F '\t' '{printf "- %s commits: %s\n", $1, $2}' top_authors.txt
               else
                 echo "- None"
               fi
               echo
               echo "### Hot Directories"
               if [ -s top_dirs.txt ]; then
                 awk -F '\t' '{printf "- %s files changed: %s\n", $1, $2}' top_dirs.txt
               else
                 echo "- None"
               fi
               echo
               echo "### CI Failures"
               if [ -s ci_failures.json ] && [ "$(jq length ci_failures.json)" -gt 0 ]; then
                 jq -r '.[] | "- [" + .severity + "] " + .title + " (" + .url + ")"' ci_failures.json
               else
                 echo "- None"
               fi
               echo
               echo "### TODOs"
               echo "- [ ] Review CI failures above and assign owners"
               if [ -s ci_failures.json ] && [ "$(jq length ci_failures.json)" -gt 0 ]; then
                 jq -r '.[] | "- [ ] Investigate PR from: " + (.title | capture("PR #(?<num>\\d+)").num // "unknown") + " — " + .severity + " — " + .url' ci_failures.json || true
               fi
               if [ -s top_dirs.txt ]; then
                 awk -F '\t' '{printf "- [ ] Review changes in %s (%s files)\n", $2, $1}' top_dirs.txt
               fi
               if [ -s top_authors.txt ]; then
                 awk -F '\t' '{printf "- [ ] Review commits by %s (%s commits)\n", $2, $1}' top_authors.txt
               fi
             } > digest.md

        - name: Create/Update Daily Digest Issue
          uses: actions/github-script@v7
          with:
             script: |
                const fs = require('fs');
                const now = new Date().toISOString().slice(0,10);
                const title = `Daily AI Digest - ${now}`;
                const digestIssues = await github.rest.search.issuesAndPullRequests({
                  q: `repo:${context.repo.owner}/${context.repo.repo} in:title "${title}"`
                });
                const body = fs.readFileSync('digest.md', 'utf8');
                if (digestIssues.data.items.length) {
                  await github.rest.issues.update({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    issue_number: digestIssues.data.items[0].number,
                    body,
                    labels: ["ai-digest"]
                  });
                } else {
                  await github.rest.issues.create({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    title,
                    body,
                    labels: ["ai-digest"]
                  });
                }
